{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the notebook\n",
    "\n",
    "This is done in this notebook in addition, so the notebook can run without being called from the main\n",
    "notebook\n",
    "\n",
    "- Load file with secrets\n",
    "- Set some constants\n",
    "- Load libraries\n",
    "\n",
    "- Load variables from the main notebook from file, this is not needed if the notbook is running from inside the main notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API secrets are not pushed to github. This is handled by placing them in a file named secrets and removing version control from that file.\n",
    "Since the file is not in the same directory as the notebooks extra code is needed to add the path to the sys search path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The secrets file containts two variables used in the Foursquare API: CLIENT_ID and CLIENT_SECRET\n",
    "It contains two variables used int the travel time API: APP_ID and API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secrets.py imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "project_folder_path = os.path.dirname(os.getcwd())\n",
    "project_folder_path\n",
    "import sys\n",
    "sys.path.insert(0, project_folder_path)\n",
    "\n",
    "import secrets\n",
    "print('secrets.py imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data path contains data loaded from the net. The sanbox accounts used to load the data have limits on the number of requests. Storing the results allows for restarting the kernal without having to make new calls to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path is :/Users/danielhaugstvedt/Developer/coursera_capstone/data/external/\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = project_folder_path + '/data/external/'\n",
    "print('Data path is :{}'.format(DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # library to handle data in a vectorized manner\n",
    "import pandas as pd # library for data analsysis\n",
    "\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import requests # library to handle requests\n",
    "import json\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import folium # map rendering library\n",
    "\n",
    "import pickle # needed to store variables\n",
    "\n",
    "import time # Try to not overload the traveltime API\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'neighborhoods_final.p'\n",
    "with open(DATA_PATH + file_name, 'rb') as infile:\n",
    "    neighborhoods_final = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'ny_venues_final.p'\n",
    "with open(DATA_PATH + file_name, 'rb') as infile:\n",
    "    ny_venues_final = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the travel time between the different neighborhoods\n",
    "\n",
    "Using the traveltime API, get the travel time between the different neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Post request example**\n",
    "\n",
    "```\n",
    "POST /v4/time-filter HTTP/1.1\n",
    "Host: api.traveltimeapp.com\n",
    "Content-Type: application/json\n",
    "Accept: application/json\n",
    "X-Application-Id: APP_ID\n",
    "X-Api-Key: API_KEY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the information in the post request example to URI and header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "URI_traveltime = 'HTTPS://api.traveltimeapp.com/v4/time-filter'\n",
    "headers = {'Host': 'api.traveltimeapp.com',\n",
    "           'Content-Type': 'application/json', \n",
    "           'Accept': 'application/json', \n",
    "           'X-Application-Id': secrets.APP_ID, # APP ID is in separate file not under version control\n",
    "           'X-Api-Key': secrets.API_KEY} # API_KEY is in separate file not under version control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuction that adds locations to the json request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_locations(locations, latitudes, longitudes):\n",
    "    \n",
    "    json_request = {'locations': [], 'departure_searches':[], 'arrival_searches':[]}\n",
    "    \n",
    "    for loc, lat, long in zip(locations, latitudes, longitudes):\n",
    "        json_request['locations'].append({\n",
    "            'id': loc,\n",
    "            'coords': {\n",
    "                'lat': lat, \n",
    "                'lng': long\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    return json_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a searches to the json request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_search(json_request, from_location, travel_time, departure_time):\n",
    "    \n",
    "    arrival_locations = []\n",
    "    for location_dic in json_request['locations']:\n",
    "        arrival_locations.append(location_dic['id'])\n",
    "        \n",
    "    del arrival_locations[arrival_locations.index(from_location)]\n",
    "    \n",
    "    json_request['departure_searches'].append({\n",
    "        'id': 'from {}'.format(from_location),\n",
    "        'departure_location_id': from_location,\n",
    "        'arrival_location_ids': arrival_locations,\n",
    "        'transportation': {'type': 'public_transport'}, \n",
    "        'departure_time' : departure_time,\n",
    "        'travel_time': travel_time,\n",
    "        'range': {\n",
    "                'enabled': True,\n",
    "                'max_results': 3,\n",
    "                'width': 600\n",
    "            },\n",
    "        'properties': ['travel_time']\n",
    "    })\n",
    "    \n",
    "    return json_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make three vectors\n",
    "\n",
    "- limits on API is 2000 arival locations\n",
    "- limits on API is 10 searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need less than 2000 locations. The number we are using is 262\n"
     ]
    }
   ],
   "source": [
    "locations = neighborhoods_final.loc[:, 'Neighborhood']\n",
    "latitudes = neighborhoods_final.loc[:, 'Latitude']\n",
    "longitudes = neighborhoods_final.loc[:, 'Longitude']\n",
    "print('We need less than 2000 locations. The number we are using is {}'.format(len(locations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if the file are stored, if not load the the data from the API\n",
    "\n",
    "When using the API, loop through all locations and do a post request where \n",
    "the location is the origin of the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to open file: /Users/danielhaugstvedt/Developer/coursera_capstone/data/external/traveltime_0_149.p\n",
      "Sucess loading from file\n",
      "150\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "locations_subset = locations[0:150]\n",
    "file_name = 'traveltime_0_149.p'\n",
    "\n",
    "try:\n",
    "    print('Trying to open file: {}'.format(DATA_PATH + file_name))\n",
    "    with open(DATA_PATH + file_name, 'rb') as infile:\n",
    "        results = pickle.load(infile)\n",
    "        print('Sucess loading from file')\n",
    "except FileNotFoundError:\n",
    "    print('Failed to load from local file, trying to load from web')\n",
    "    results = []\n",
    "    for location in locations_subset:\n",
    "        json_request_setup = add_locations(locations, latitudes, longitudes)\n",
    "        json_request = add_search(json_request_setup, location, 60*60*1.5, '2019-01-11T13:00:00Z')\n",
    "        \n",
    "        # The fallback should not be used if you are not really sure \n",
    "        #result = requests.post(URI_traveltime, headers=headers, json=json_request)\n",
    "        print('{} request returned with status code: {} and reason: {}'.format(location, result.status_code, result.reason))\n",
    "        if result.status_code != 200:\n",
    "            break\n",
    "            \n",
    "        json_result = result.json()\n",
    "        results.append(json_result['results'])\n",
    "        #time.sleep(60) # sleep 60 s, this is used when doing many queries. The api can get overloaded.\n",
    "        \n",
    "    with open(DATA_PATH + file_name, 'wb') as outfile:\n",
    "        pickle.dump(results, outfile)\n",
    "results_0_149 = results\n",
    "print(len(locations_subset))\n",
    "print(len(results_0_149))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to open file: /Users/danielhaugstvedt/Developer/coursera_capstone/data/external/traveltime_150_192.p\n",
      "Sucess loading from file\n",
      "43\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "locations_subset = locations[150:193]\n",
    "file_name = 'traveltime_150_192.p'\n",
    "\n",
    "try:\n",
    "    print('Trying to open file: {}'.format(DATA_PATH + file_name))\n",
    "    with open(DATA_PATH + file_name, 'rb') as infile:\n",
    "        results = pickle.load(infile)\n",
    "        print('Sucess loading from file')\n",
    "except FileNotFoundError:\n",
    "    print('Failed to load from local file, trying to load from web')\n",
    "    results = []\n",
    "    for location in locations_subset:\n",
    "        json_request_setup = add_locations(locations, latitudes, longitudes)\n",
    "        json_request = add_search(json_request_setup, location, 60*60*1.5, '2019-01-11T13:00:00Z')\n",
    "        \n",
    "        # The fallback should not be used if you are not really sure \n",
    "        #result = requests.post(URI_traveltime, headers=headers, json=json_request)\n",
    "        print('{} request returned with status code: {} and reason: {}'.format(location, result.status_code, result.reason))\n",
    "        if result.status_code != 200:\n",
    "            break\n",
    "            \n",
    "        json_result = result.json()\n",
    "        results.append(json_result['results'])\n",
    "        #time.sleep(60) # sleep 60 s, this is used when doing many queries. The api can get overloaded.\n",
    "        \n",
    "    with open(DATA_PATH + file_name, 'wb') as outfile:\n",
    "        pickle.dump(results, outfile)\n",
    "        \n",
    "results_150_192 = results\n",
    "print(len(locations_subset))\n",
    "print(len(results_150_192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to open file: /Users/danielhaugstvedt/Developer/coursera_capstone/data/external/traveltime_193_260.p\n",
      "Sucess loading from file\n",
      "68\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "locations_subset = locations[193:261]\n",
    "file_name = 'traveltime_193_260.p'\n",
    "\n",
    "try:\n",
    "    print('Trying to open file: {}'.format(DATA_PATH + file_name))\n",
    "    with open(DATA_PATH + file_name, 'rb') as infile:\n",
    "        results = pickle.load(infile)\n",
    "        print('Sucess loading from file')\n",
    "except FileNotFoundError:\n",
    "    print('Failed to load from local file, trying to load from web')\n",
    "    results = []\n",
    "    for location in locations_subset:\n",
    "        json_request_setup = add_locations(locations, latitudes, longitudes)\n",
    "        json_request = add_search(json_request_setup, location, 60*60*1.5, '2019-01-11T13:00:00Z')\n",
    "        \n",
    "        result = requests.post(URI_traveltime, headers=headers, json=json_request)\n",
    "        print('{} request returned with status code: {} and reason: {}'.format(location, result.status_code, result.reason))\n",
    "        if result.status_code != 200:\n",
    "            break\n",
    "            \n",
    "        json_result = result.json()\n",
    "        results.append(json_result['results'])\n",
    "        time.sleep(60) # sleep 60 s, this is used when doing many queries. The api can get overloaded.\n",
    "        \n",
    "    with open(DATA_PATH + file_name, 'wb') as outfile:\n",
    "        pickle.dump(results, outfile)\n",
    "        \n",
    "results_193_260 = results\n",
    "print(len(locations_subset))\n",
    "print(len(results_193_260))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to open file: /Users/danielhaugstvedt/Developer/coursera_capstone/data/external/traveltime_261.p\n",
      "Sucess loading from file\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "locations_subset = locations[261:]\n",
    "file_name = 'traveltime_261.p'\n",
    "\n",
    "try:\n",
    "    print('Trying to open file: {}'.format(DATA_PATH + file_name))\n",
    "    with open(DATA_PATH + file_name, 'rb') as infile:\n",
    "        results = pickle.load(infile)\n",
    "        print('Sucess loading from file')\n",
    "except FileNotFoundError:\n",
    "    print('Failed to load from local file, trying to load from web')\n",
    "    results = []\n",
    "    for location in locations_subset:\n",
    "        json_request_setup = add_locations(locations, latitudes, longitudes)\n",
    "        json_request = add_search(json_request_setup, location, 60*60*1.5, '2019-01-11T13:00:00Z')\n",
    "        \n",
    "        result = requests.post(URI_traveltime, headers=headers, json=json_request)\n",
    "        print('{} request returned with status code: {} and reason: {}'.format(location, result.status_code, result.reason))\n",
    "        if result.status_code != 200:\n",
    "            break\n",
    "            \n",
    "        json_result = result.json()\n",
    "        results.append(json_result['results'])\n",
    "        time.sleep(60) # sleep 60 s, this is used when doing many queries. The api can get overloaded.\n",
    "        \n",
    "    with open(DATA_PATH + file_name, 'wb') as outfile:\n",
    "        pickle.dump(results, outfile)\n",
    "        \n",
    "results_261 = results\n",
    "print(len(locations_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_0_149) + len(results_150_192) + len(results_193_260) + len(results_261)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the travel time into json into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_time_df = (pd.DataFrame(index=locations, columns=locations) # Data frame with NaNs\n",
    "     .fillna(0))\n",
    "\n",
    "for result in results_0_149:\n",
    "    result = result[0] # get the dictionary from the array\n",
    "    from_location = ' '.join(result['search_id'].split(\" \")[1:])\n",
    "    for to_location_dic in result['locations']:\n",
    "        to_location = to_location_dic['id']\n",
    "        travel_time = to_location_dic['properties'][0]['travel_time']\n",
    "        travel_time_df.loc[from_location, to_location] = travel_time / (60*60) # Hours\n",
    "        \n",
    "for result in results_150_192:\n",
    "    result = result[0] # get the dictionary from the array\n",
    "    from_location = ' '.join(result['search_id'].split(\" \")[1:])\n",
    "    for to_location_dic in result['locations']:\n",
    "        to_location = to_location_dic['id']\n",
    "        travel_time = to_location_dic['properties'][0]['travel_time']\n",
    "        travel_time_df.loc[from_location, to_location] = travel_time / (60*60) # Hours\n",
    "        \n",
    "for result in results_193_260:\n",
    "    result = result[0] # get the dictionary from the array\n",
    "    from_location = ' '.join(result['search_id'].split(\" \")[1:])\n",
    "    for to_location_dic in result['locations']:\n",
    "        to_location = to_location_dic['id']\n",
    "        travel_time = to_location_dic['properties'][0]['travel_time']\n",
    "        travel_time_df.loc[from_location, to_location] = travel_time / (60*60) # Hours\n",
    "        \n",
    "for result in results_261:\n",
    "    result = result[0] # get the dictionary from the array\n",
    "    from_location = ' '.join(result['search_id'].split(\" \")[1:])\n",
    "    for to_location_dic in result['locations']:\n",
    "        to_location = to_location_dic['id']\n",
    "        travel_time = to_location_dic['properties'][0]['travel_time']\n",
    "        travel_time_df.loc[from_location, to_location] = travel_time / (60*60) # Hours\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(travel_time_df.sum(axis=0)==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up values you do not want to pass back to the main notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del results_261\n",
    "del results_193_260\n",
    "del results_150_192\n",
    "del results_0_149\n",
    "del results\n",
    "del locations_subset\n",
    "del URI_traveltime\n",
    "del headers\n",
    "del to_location      \n",
    "del to_location_dic\n",
    "del travel_time \n",
    "del from_location"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coursera_capstone]",
   "language": "python",
   "name": "conda-env-coursera_capstone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
